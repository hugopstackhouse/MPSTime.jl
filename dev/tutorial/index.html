<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial: Classification · MPSTime</title><meta name="title" content="Tutorial: Classification · MPSTime"/><meta property="og:title" content="Tutorial: Classification · MPSTime"/><meta property="twitter:title" content="Tutorial: Classification · MPSTime"/><meta name="description" content="Documentation for MPSTime."/><meta property="og:description" content="Documentation for MPSTime."/><meta property="twitter:description" content="Documentation for MPSTime."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.svg" alt="MPSTime logo"/><img class="docs-dark-only" src="../assets/logo-dark.svg" alt="MPSTime logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>Tutorial: Classification</a><ul class="internal"><li><a class="tocitem" href="#Demo-dataset"><span>Demo dataset</span></a></li><li><a class="tocitem" href="#Training-an-MPS"><span>Training an MPS</span></a></li><li><a class="tocitem" href="#Hyperparameters"><span>Hyperparameters</span></a></li><li><a class="tocitem" href="#Classification"><span>Classification</span></a></li><li><a class="tocitem" href="#Imputation"><span>Imputation</span></a></li><li><a class="tocitem" href="#Training-with-a-custom-basis"><span>Training with a custom basis</span></a></li><li><a class="tocitem" href="#Docstrings"><span>Docstrings</span></a></li></ul></li><li><a class="tocitem" href="../imputation/">Imputation</a></li><li><a class="tocitem" href="../synthdatagen/">Synthetic Data Generation</a></li><li><a class="tocitem" href="../encodings/">Encodings</a></li><li><a class="tocitem" href="../tools/">Tools</a></li><li><a class="tocitem" href="../docstrings/">Docstrings</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial: Classification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial: Classification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/jmoo2880/MPSTime.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/jmoo2880/MPSTime.jl/blob/main/docs/src/tutorial.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorial"><a class="docs-heading-anchor" href="#Tutorial">Tutorial</a><a id="Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorial" title="Permalink"></a></h1><p>This tutorial for MPSTime will take you through the basic steps needed to fit an MPS to a time-series dataset.</p><h2 id="Demo-dataset"><a class="docs-heading-anchor" href="#Demo-dataset">Demo dataset</a><a id="Demo-dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Demo-dataset" title="Permalink"></a></h2><p>First, import or generate your data. Here, we generate a two class &quot;noisy trendy sine&quot; dataset for the sake of demonstration, but if you have a dataset in mind, you can skip to the next section. Our demonstration dataset consists of a sine function with a randomised phase, plus a linear trend, plus some normally distributed noise. Each time series in class <span>$c$</span> at time <span>$t$</span> is given by:</p><p class="math-container">\[x^c_t = \sin{\left(\frac{2\pi}{20}t + \psi\right)} + \frac{mt}{T} + \sigma_c n_t\,,\]</p><p>where <span>$m$</span> is the slope of a linear trend, <span>$\psi \in [0, 2\pi)$</span> is a uniformly random phase offset, <span>$\sigma_c$</span> is the noise scale, and <span>$n_t \sim \mathcal{N}(0,1)$</span> are  normally distributed random variables. </p><p>The two classes will be distinguished by their noise levels. The class one time series <span>$x^1$</span> have <span>$\sigma_1 = 0.1$</span>, and the class two time series <span>$x^2$</span> have <span>$\sigma_2 = 0.9$</span>. The below code sets this up</p><pre><code class="language-Julia hljs"># fix rng seed
using Random
rng = Xoshiro(1)


# trendy sine function
function trendy_sine(T::Integer, n_inst::Integer, noise_std::Real, rng)
    X = Matrix{Float64}(undef, n_inst, T)
    ts = 1:T
    for series in eachrow(X)
        phase = 2 * pi * rand(rng)
        @. series = sin(pi/10 *ts + phase) + 3 * ts / T + noise_std * randn(rng) 
    end
    return X
end

# dataset size
ntimepoints = 100
ntrain_instances = 300
ntest_instances = 200

# define data. Class one has sigma = 0.1, class 2 has sigma = 0.9
X_train = vcat(trendy_sine(ntimepoints, ntrain_instances ÷ 2, 0.1, rng), trendy_sine(ntimepoints, ntrain_instances ÷ 2, 0.9, rng));
y_train = vcat(fill(1, ntrain_instances ÷ 2), fill(2, ntrain_instances ÷ 2));
X_test = vcat(trendy_sine(ntimepoints, ntest_instances ÷ 2, 0.1, rng), trendy_sine(ntimepoints, ntest_instances ÷ 2, 0.9, rng));
y_test = vcat(fill(1, ntest_instances ÷ 2), fill(2, ntest_instances ÷ 2));
</code></pre><h2 id="Training-an-MPS"><a class="docs-heading-anchor" href="#Training-an-MPS">Training an MPS</a><a id="Training-an-MPS-1"></a><a class="docs-heading-anchor-permalink" href="#Training-an-MPS" title="Permalink"></a></h2><p>For the most basic use of fitMPS, select your hyperparameters, and run the <a href="#MPSTime.fitMPS-Tuple{Matrix, Vector, Matrix, Vector, MPSOptions, Nothing}"><code>fitMPS</code></a> function. Some (truncated) output from our noisy trendy sine datam with default hyperparameters is given below. </p><pre><code class="language-Julia hljs">julia&gt; opts = MPSOptions() # calling this with no arguments gives default hyperparameters
julia&gt; mps, info, test_states = fitMPS(X_train, y_train, X_test, y_test, opts);
Generating initial weight MPS with bond dimension χ_init = 4
        using random state 1234.
Initialising train states.
Initialising test states.
Using 1 iterations per update.
Training KL Div. 122.43591167452153 | Training acc. 0.51.
Test KL Div. 121.83350501986212 | Testing acc. 0.55.

Test conf: [55 45; 45 55].
Using optimiser CustomGD with the &quot;TSGO&quot; algorithm
Starting backward sweeep: [1/5]
Backward sweep finished.
Starting forward sweep: [1/5]
    ...

MPS normalised!

Training KL Div. -18.149569463050405 | Training acc. 1.0.
Test KL Div. -1.2806885386973699 | Testing acc. 0.925.

Test conf: [100 0; 15 85]. </code></pre><p><a href="#MPSTime.fitMPS-Tuple{Matrix, Vector, Matrix, Vector, MPSOptions, Nothing}"><code>fitMPS</code></a> doesn&#39;t use <code>X_test</code> or <code>y_test</code> for anything except printing performance evaluations, so it is safe to leave them blank. For unsupervised learning, input a dataset with only one class, or only pass <code>X_train</code> ( <code>y_train</code> has a default value of <code>zeros(Int, size(X_train, 1))</code> ).</p><p>The <code>mps::TrainedMPS</code> can be passed directly to <a href="#MPSTime.classify-Tuple{TrainedMPS, AbstractMatrix, MPSOptions}"><code>classify</code></a> for classification, or <a href="../imputation/#MPSTime.init_imputation_problem-Tuple{TrainedMPS, Matrix}"><code>init_imputation_problem</code></a> to set up an imputation problem. The info <code>info</code> provides a short training summary, which can be pretty-printed with <a href="#MPSTime.sweep_summary-Tuple{Any}"><code>sweep_summary</code></a>.</p><p>You can use <code>test_states</code> to print a summary of the MPS performance on the test set.</p><pre><code class="language-Julia hljs">Julia&gt; get_training_summary(mps, test_states; print_stats=true)

         Overlap Matrix
┌──────┬───────────┬───────────┐
│      │   |ψ1⟩    │   |ψ2⟩    │
├──────┼───────────┼───────────┤
│ ⟨ψ1| │ 5.022e-01 │ 2.216e-04 │
├──────┼───────────┼───────────┤
│ ⟨ψ2| │ 2.216e-04 │ 4.978e-01 │
└──────┴───────────┴───────────┘
          Confusion Matrix
┌──────────┬───────────┬───────────┐
│          │ Pred. |1⟩ │ Pred. |2⟩ │
├──────────┼───────────┼───────────┤
│ True |1⟩ │       100 │         0 │
├──────────┼───────────┼───────────┤
│ True |2⟩ │        15 │        85 │
└──────────┴───────────┴───────────┘
┌───────────────────┬───────────┬──────────┬──────────┬─────────────┬─────────┬───────────┐
│ test_balanced_acc │ train_acc │ test_acc │ f1_score │ specificity │  recall │ precision │
│           Float64 │   Float64 │  Float64 │  Float64 │     Float64 │ Float64 │   Float64 │
├───────────────────┼───────────┼──────────┼──────────┼─────────────┼─────────┼───────────┤
│             0.925 │       1.0 │    0.925 │ 0.924576 │       0.925 │   0.925 │  0.934783 │
└───────────────────┴───────────┴──────────┴──────────┴─────────────┴─────────┴───────────┘</code></pre><h2 id="Hyperparameters"><a class="docs-heading-anchor" href="#Hyperparameters">Hyperparameters</a><a id="Hyperparameters-1"></a><a class="docs-heading-anchor-permalink" href="#Hyperparameters" title="Permalink"></a></h2><p>There are number of hyperparameters and data preprocessing options that can be specified using <code>MPSOptions(; key=value)</code></p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPSTime.MPSOptions" href="#MPSTime.MPSOptions"><code>MPSTime.MPSOptions</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MPSOptions(; &lt;Keyword Arguments&gt;)</code></pre><p>Set the hyperparameters and other options for fitMPS. </p><p><strong>Fields:</strong></p><p><strong>Logging</strong></p><ul><li><code>verbosity::Int=1</code>: How much debug/progress info to print to the terminal while optimising the MPS. Higher numbers mean more output</li><li><code>log_level::Int=3</code>: How much statistical output. 0 for nothing, &gt;0 to print losses, accuracies, and confusion matrix at each step (noticeable) computational overhead) #TODO implement finer grain control</li><li><code>track_cost::Bool=false</code>: Whether to print the cost at each Bond tensor site to the terminal while training, mostly useful for debugging new cost functions or optimisers (<strong>HUGE</strong> computational overhead)</li></ul><p><strong>MPS Training Hyperparameters</strong></p><ul><li><code>nsweeps::Int=5</code>: Number of MPS optimisation sweeps to perform (Both forwards and Backwards)</li><li><code>chi_max::Int=25</code>: Maximum bond dimension allowed within the MPS during the SVD step</li><li><code>eta::Float64=0.01</code>: The learning rate. For gradient descent methods, this is the step size. For Optim and OptimKit this serves as the initial step size guess input into the linesearch</li><li><code>d::Int=5</code>: The dimension of the feature map or &quot;Encoding&quot;. This is the true maximum dimension of the feature vectors. For a splitting encoding, d = num<em>splits * aux</em>basis_dim</li><li><code>cutoff::Float64=1E-10</code>: Size based cutoff for the number of singular values in the SVD (See Itensors SVD documentation)</li><li><code>dtype::DataType=Float64 or ComplexF64 depending on encoding</code>: The datatype of the elements of the MPS. Supports the arbitrary precsion types such as BigFloat and Complex{BigFloat}</li><li><code>exit_early::Bool=false</code>: Stops training if training accuracy is 1 at the end of any sweep.</li></ul><p><strong>Encoding Options</strong></p><ul><li><code>encoding::Symbol=:Legendre</code>: The encoding to use, including :Stoudenmire, :Fourier, :Legendre, :SLTD, :Custom, etc. see Encoding docs for a complete list. Can be just a time (in)dependent orthonormal basis, or a time (in)dependent basis mapped onto a number of &quot;splits&quot; which distribute tighter basis functions where the sites of a timeseries are more likely to be measured.  </li><li><code>projected_basis::Bool=false</code>: Whether toproject a basis onto the training data at each time. Normally, when specifying a basis of dimension <em>d</em>, the first <em>d</em> lowest order terms are used. When project=true, the training data is used to construct a pdf of the possible timeseries amplitudes at each time point. The first <em>d</em> largest terms of this pdf expanded in a series are used to select the basis terms.</li><li><code>aux_basis_dim::Int=2</code>: Unused for standard encodings. If the encoding is a SplitBasis, serves as the auxilliary dimension of a basis mapped onto the split encoding, so that the number of histogram bins = <em>d</em> / <em>aux<em>basis</em>dim</em>. </li><li><code>encode_classes_separately::Bool=false</code>: Only relevant for data driven bases. If true, then data is split up by class before being encoded. Functionally, this causes the encoding method to vary depending on the class</li></ul><p><strong>Data Preprocessing and MPS initialisation</strong></p><ul><li><code>sigmoid_transform::Bool</code>: Whether to apply a sigmoid transform to the data before minmaxing. This has the form</li></ul><p class="math-container">\[\boldsymbol{X&#39;} = \left(1 + \exp{-\frac{\boldsymbol{X}-m_{\boldsymbol{X}}}{r_{\boldsymbol{X}} / 1.35}}\right)^{-1}\]</p><p>where <span>$\boldsymbol{X}$</span> is the un-normalized time-series data matrix, <span>$m_{\boldsymbol{X}}$</span> is the median of <span>$\boldsymbol{X}$</span> and <span>$r_{\boldsymbol{X}}$</span>is its interquartile range.</p><ul><li><code>minmax::Bool</code>: Whether to apply a minmax norm to <code>[0,1]</code> before encoding. This has the form</li></ul><p class="math-container">\[\boldsymbol{X&#39;} =  \frac{\boldsymbol{X} - x&#39;_{\text{min}}}{x&#39;_{\text{max}} - x&#39;_{\text{min}}},\]</p><p>where <span>$\boldsymbol{X&#39;&#39;}$</span> is the scaled robust-sigmoid transformed data matrix, <span>$x&#39;_\text{min}$</span> and <span>$x&#39;_\text{max}$</span> are the minimum and maximum of <span>$\boldsymbol{X&#39;}$</span>.</p><ul><li><p><code>data_bounds::Tuple{Float64, Float64} = (0.,1.)</code>: The region to bound the data to if minmax=true. This is separate from the encoding domain. All encodings expect data to be scaled scaled between 0 and 1. Setting the data bounds a bit away from [0,1] can help when your basis has poor support near its boundaries.</p></li><li><p><code>init_rng::Int</code>: Random seed used to generate the initial MPS</p></li><li><p><code>chi_init::Int</code>: Initial bond dimension of the random MPS</p></li></ul><p><strong>Loss Functions and Optimisation Methods</strong></p><ul><li><p><code>loss_grad::Symbol=:KLD</code>: The type of cost function to use for training the MPS, typically Mean Squared Error (:MSE) or KL Divergence (:MSE), but can also be a weighted sum of the two (:Mixed)</p></li><li><p><code>bbopt::Symbol=:TSGO</code>: Which local Optimiser to use, builtin options are symbol gradient descent (:GD), or gradient descent with a TSGO rule (:TSGO). Other options are Conjugate Gradient descent using either the Optim or OptimKit packages (:Optim or :OptimKit respectively). The CGD methods work well for MSE based loss functions, but seem to perform poorly for KLD base loss functions.</p></li><li><p><code>rescale::Tuple{Bool,Bool}=(false,true)</code>: Has the form <code>rescale = (before::Bool, after::Bool)</code>. Where to enforce the normalisation of the MPS during training, either calling normalise!(<em>Bond Tensor</em>) before or after BT is updated. Note that for an MPS that starts in canonical form, rescale = (true,true) will train identically to rescale = (false, true) but may be less performant.</p></li><li><p><code>update_iters::Int=1</code>: Maximum number of optimiser iterations to perform for each bond tensor optimisation. E.G. The number of steps of (Conjugate) Gradient Descent used by TSGO, Optim or OptimKit</p></li><li><p><code>train_classes_separately::Bool=false</code>: Whether the the trainer optimises the total MPS loss over all classes or whether it considers each class as a separate problem. Should make very little diffence</p></li></ul><p><strong>Debug</strong></p><ul><li><code>return_encoding_meta_info::Bool=false</code>: Debug flag: Whether to return the normalised data as well as the histogram bins for the splitbasis types</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/Structs/options.jl#L40-L101">source</a></section><section><div><p>Convert the internal Options type into a serialisable MPSOptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/Structs/options.jl#L337">source</a></section></article><p>You can also print a formatted table of options with <a href="#MPSTime.print_opts"><code>print_opts</code></a> (beware long output)</p><pre><code class="language-Julia hljs">print_opts(opts)</code></pre><pre><code class="nohighlight hljs">┌────────────┬──────────────┬──────────────────────────┬────────┬───────────────────────────┬──────────┬─────────┬─────────┬──────────┬──────────────────┬───────────────────┬───────────┬─────────────────────────┬──────────┬───────┬────────────┬───────────────────────────┬─────────┬───────────────────┬───────────────┬────────┬───────────┬───────────┬─────────────────┬─────────┐
│ track_cost │ update_iters │ train_classes_separately │ minmax │ return_encoding_meta_info │    dtype │ nsweeps │  cutoff │ chi_init │         encoding │           rescale │ loss_grad │             data_bounds │ init_rng │     d │ exit_early │ encode_classes_separately │     eta │ sigmoid_transform │ aux_basis_dim │  bbopt │ log_level │ verbosity │ projected_basis │ chi_max │
│       Bool │        Int64 │                     Bool │   Bool │                      Bool │ DataType │   Int64 │ Float64 │    Int64 │           Symbol │ Tuple{Bool, Bool} │    Symbol │ Tuple{Float64, Float64} │    Int64 │ Int64 │       Bool │                      Bool │ Float64 │              Bool │         Int64 │ Symbol │     Int64 │     Int64 │            Bool │   Int64 │
├────────────┼──────────────┼──────────────────────────┼────────┼───────────────────────────┼──────────┼─────────┼─────────┼──────────┼──────────────────┼───────────────────┼───────────┼─────────────────────────┼──────────┼───────┼────────────┼───────────────────────────┼─────────┼───────────────────┼───────────────┼────────┼───────────┼───────────┼─────────────────┼─────────┤
│      false │            1 │                    false │   true │                     false │  Float64 │       5 │ 1.0e-10 │        4 │ Legendre_No_Norm │     (false, true) │       KLD │              (0.0, 1.0) │     1234 │     5 │      false │                     false │    0.01 │              true │             2 │   TSGO │         3 │         1 │           false │      25 │
└────────────┴──────────────┴──────────────────────────┴────────┴───────────────────────────┴──────────┴─────────┴─────────┴──────────┴──────────────────┴───────────────────┴───────────┴─────────────────────────┴──────────┴───────┴────────────┴───────────────────────────┴─────────┴───────────────────┴───────────────┴────────┴───────────┴───────────┴─────────────────┴─────────┘

julia&gt; </code></pre><h2 id="Classification"><a class="docs-heading-anchor" href="#Classification">Classification</a><a id="Classification-1"></a><a class="docs-heading-anchor-permalink" href="#Classification" title="Permalink"></a></h2><p>To predict the class of unseen data, use the <a href="#MPSTime.classify-Tuple{TrainedMPS, AbstractMatrix, MPSOptions}"><code>classify</code></a> function.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPSTime.classify-Tuple{TrainedMPS, AbstractMatrix, MPSOptions}" href="#MPSTime.classify-Tuple{TrainedMPS, AbstractMatrix, MPSOptions}"><code>MPSTime.classify</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-Julia hljs">classify(mps::TrainedMPS, X_test::AbstractMatrix, opts::AbstractMPSOptions)) -&gt; (predictions::Vector)</code></pre><p>Use the <code>mps</code> to predict the class of the rows of <code>X_test</code> by computing the maximum overlap.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">julia&gt; W, info, test_states = fitMPS( X_train, y_train, opts);
julia&gt; preds  = classify(W, X_test, opts); # make some predictions
julia&gt; mean(preds .== y_test)
0.9504373177842566</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/summary.jl#L148-L162">source</a></section></article><p>For example, for the noisy trendy sine from earlier:</p><pre><code class="language-Julia hljs">julia&gt; predictions = classify(mps, X_test, opts);
julia&gt; using Statistics
julia&gt; mean(predictions .== y_test)
0.925</code></pre><h2 id="Imputation"><a class="docs-heading-anchor" href="#Imputation">Imputation</a><a id="Imputation-1"></a><a class="docs-heading-anchor-permalink" href="#Imputation" title="Permalink"></a></h2><p>See <a href="../imputation/#Imputation_top">Imputation</a></p><h2 id="Training-with-a-custom-basis"><a class="docs-heading-anchor" href="#Training-with-a-custom-basis">Training with a custom basis</a><a id="Training-with-a-custom-basis-1"></a><a class="docs-heading-anchor-permalink" href="#Training-with-a-custom-basis" title="Permalink"></a></h2><p>To train with a custom basis, first, declare a custom basis with <a href="../encodings/#MPSTime.function_basis"><code>function_basis</code></a>, and pass it in as the last argument to <a href="#MPSTime.fitMPS-Tuple{Matrix, Vector, Matrix, Vector, MPSOptions, Nothing}"><code>fitMPS</code></a>. For this to work, the encoding hyperparameter must be set to <code>:Custom</code> in <code>MPSOptions</code></p><pre><code class="language-Julia hljs">encoding = function_basis(...)
fitMPS(X_train, y_train, X_test, y_test, MPSOptions(; encoding=:Custom), encoding)</code></pre><h2 id="Docstrings"><a class="docs-heading-anchor" href="#Docstrings">Docstrings</a><a id="Docstrings-1"></a><a class="docs-heading-anchor-permalink" href="#Docstrings" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPSTime.fitMPS-Tuple{Matrix, Vector, Matrix, Vector, MPSOptions, Nothing}" href="#MPSTime.fitMPS-Tuple{Matrix, Vector, Matrix, Vector, MPSOptions, Nothing}"><code>MPSTime.fitMPS</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-Julia hljs">fitMPS(X_train::AbstractMatrix, 
       y_train::AbstractVector=zeros(Int, size(X_train, 1)), 
       X_test::AbstractMatrix=zeros(0,0), 
       y_test::AbstractVector=zeros(Int, 0), 
       opts::AbstractMPSOptions=MPSOptions(),
       custom_encoding::Union{Encoding, Nothing}=nothing) -&gt; (MPS::TrainedMPS, training_info::Dict, encoded_test_states::EncodedTimeSeriesSet)</code></pre><p>Train an MPS on the data <code>X_train</code> using the hyperparameters <code>opts</code>, see <a href="#MPSTime.MPSOptions"><code>MPSOptions</code></a>. The number of classes are determined by the entries of <code>y_train</code>. Fo</p><p>Returns a trained MPS, a dictionary containing training info, and the encoded test states. <code>X_test</code> and <code>y_test</code> are used only to print performance evaluations, and may be empty.  The return value <code>encoded_test_states</code> will be sorted by class, so predictions shouldn&#39;t be compared directly to <code>y_test</code>. The <code>custom_encoding</code> argument allows the use of user defined custom encodings, see <a href="../encodings/#MPSTime.function_basis"><code>function_basis</code></a>. This requires that <code>encoding=:Custom</code> is specified in <a href="#MPSTime.MPSOptions"><code>MPSOptions</code></a></p><p>See also: <a href="../encodings/#MPSTime.Encoding"><code>Encoding</code></a></p><p><strong>Example</strong></p><p>See ??fitMPS to for a more verbose example</p><pre><code class="nohighlight hljs">julia&gt; opts = MPSOptions(; d=5, chi_max=30, encoding=:Legendre, eta=0.05);
julia&gt; print_opts(opts) # Prints options as a table
       ...
julia&gt; W, info, test_states = fitMPS( X_train, y_train, X_test, y_test, opts);
Generating initial weight MPS with bond dimension χ_init = 4
        using random state 1234.
Initialising train states.
Using 1 iterations per update.
Training KL Div. 28.213032851945012 | Training acc. 0.31343283582089554.
Using optimiser CustomGD with the &quot;TSGO&quot; algorithm
Starting backward sweeep: [1/5]
        ...

Starting forward sweep: [5/5]
Finished sweep 5. Time for sweep: 0.76s
Training KL Div. -12.577920427063361 | Training acc. 1.0.

MPS normalised!

Training KL Div. -12.57792042706337 | Training acc. 1.0.
Test KL Div. -9.815236609211746 | Testing acc. 0.9504373177842566.

Test conf: [497 16; 35 481].

julia&gt; 
</code></pre><p><strong>Extended help</strong></p><pre><code class="nohighlight hljs">julia&gt; Using JLD2 # load some data
julia&gt; dloc = &quot;test/Data/italypower/datasets/ItalyPowerDemandOrig.jld2&quot;
julia&gt; f = jldopen(dloc, &quot;r&quot;) 
           X_train = read(f, &quot;X_train&quot;)
           y_train = read(f, &quot;y_train&quot;)
           X_test = read(f, &quot;X_test&quot;)
           y_test = read(f, &quot;y_test&quot;)
       close(f);
julia&gt; opts = MPSOptions(; d=5, chi_max=30, encoding=:Legendre, eta=0.05);
julia&gt; print_opts(opts) # Prints options as a table
       ...
julia&gt; W, info, test_states = fitMPS( X_train, y_train, X_test, y_test, opts);
Generating initial weight MPS with bond dimension χ_init = 4
        using random state 1234.
Initialising train states.
Using 1 iterations per update.
Training KL Div. 28.213032851945012 | Training acc. 0.31343283582089554.
Using optimiser CustomGD with the &quot;TSGO&quot; algorithm
Starting backward sweeep: [1/5]
        ...

Starting forward sweep: [5/5]
Finished sweep 5. Time for sweep: 0.76s
Training KL Div. -12.577920427063361 | Training acc. 1.0.

MPS normalised!

Training KL Div. -12.57792042706337 | Training acc. 1.0.
Test KL Div. -9.815236609211746 | Testing acc. 0.9504373177842566.

Test conf: [497 16; 35 481].

julia&gt; get_training_summary(W, test_states; print_stats=true);
         Overlap Matrix
┌──────┬───────────┬───────────┐
│      │   |ψ0⟩    │   |ψ1⟩    │
├──────┼───────────┼───────────┤
│ ⟨ψ0| │ 5.074e-01 │ 1.463e-02 │
├──────┼───────────┼───────────┤
│ ⟨ψ1| │ 1.463e-02 │ 4.926e-01 │
└──────┴───────────┴───────────┘
          Confusion Matrix
┌──────────┬───────────┬───────────┐
│          │ Pred. |0⟩ │ Pred. |1⟩ │
├──────────┼───────────┼───────────┤
│ True |0⟩ │       497 │        16 │
├──────────┼───────────┼───────────┤
│ True |1⟩ │        35 │       481 │
└──────────┴───────────┴───────────┘
┌───────────────────┬───────────┬──────────┬──────────┬─────────────┬──────────┬───────────┐
│ test_balanced_acc │ train_acc │ test_acc │ f1_score │ specificity │   recall │ precision │
│           Float64 │   Float64 │  Float64 │  Float64 │     Float64 │  Float64 │   Float64 │
├───────────────────┼───────────┼──────────┼──────────┼─────────────┼──────────┼───────────┤
│          0.950491 │       1.0 │ 0.950437 │ 0.950425 │    0.950491 │ 0.950491 │  0.951009 │
└───────────────────┴───────────┴──────────┴──────────┴─────────────┴──────────┴───────────┘

julia&gt; sweep_summary(info)
┌────────────────┬──────────┬───────────────┬───────────────┬───────────────┬───────────────┬───────────────┬────────────┬──────────┐
│                │ Initial  │ After Sweep 1 │ After Sweep 2 │ After Sweep 3 │ After Sweep 4 │ After Sweep 5 │ After Norm │   Mean   │
├────────────────┼──────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼────────────┼──────────┤
│ Train Accuracy │ 0.313433 │      1.0      │      1.0      │      1.0      │      1.0      │      1.0      │    1.0     │   1.0    │
├────────────────┼──────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼────────────┼──────────┤
│  Test Accuracy │ 0.409135 │   0.947522    │   0.951409    │   0.948494    │   0.948494    │   0.950437    │  0.950437  │ 0.949271 │
├────────────────┼──────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼────────────┼──────────┤
│  Train KL Div. │  28.213  │   -11.7855    │    -12.391    │   -12.4831    │   -12.5466    │   -12.5779    │  -12.5779  │ -12.3568 │
├────────────────┼──────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼────────────┼──────────┤
│   Test KL Div. │ 27.7435  │   -9.12893    │   -9.73479    │   -9.79248    │    -9.8158    │   -9.81524    │  -9.81524  │ -9.65745 │
├────────────────┼──────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼────────────┼──────────┤
│     Time taken │   0.0    │   0.658366    │    0.75551    │   0.719035    │   0.718444    │    1.16256    │    NaN     │ 0.802783 │
└────────────────┴──────────┴───────────────┴───────────────┴───────────────┴───────────────┴───────────────┴────────────┴──────────┘
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/Training/RealRealHighDimension.jl#L380-L503">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPSTime.sweep_summary-Tuple{Any}" href="#MPSTime.sweep_summary-Tuple{Any}"><code>MPSTime.sweep_summary</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-Julia hljs">sweep_summary(info; io::IO=stdin)</code></pre><p>Print a pretty summary of what happened in every sweep</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/summary.jl#L364-L371">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPSTime.get_training_summary-Tuple{TrainedMPS, EncodedTimeSeriesSet}" href="#MPSTime.get_training_summary-Tuple{TrainedMPS, EncodedTimeSeriesSet}"><code>MPSTime.get_training_summary</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-Julia hljs">get_training_summary(mps::TrainedMPS, 
                     test_states::EncodedTimeSeriesSet;  
                     print_stats::Bool=false, 
                     io::IO=stdin) -&gt; stats::Dict</code></pre><p>Print a summary of the training process of <code>mps</code>, with performane evaluated on <code>test_states</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/summary.jl#L351-L360">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MPSTime.print_opts" href="#MPSTime.print_opts"><code>MPSTime.print_opts</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">print_opts(opts::AbstractMPSOptions; io::IO=stdin)</code></pre><p>Print the MPSOptions struct in a table.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmoo2880/MPSTime.jl/blob/4544236220c79f971ebda87e08fb52053e91314d/src/summary.jl#L403-L408">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Introduction</a><a class="docs-footer-nextpage" href="../imputation/">Imputation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Tuesday 24 December 2024 02:11">Tuesday 24 December 2024</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
