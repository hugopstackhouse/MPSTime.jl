{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 06:52:08 [INFO]: Have set the random seed as 1234 for numpy and pytorch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# script version of the imputation benchmarks notebook for running on the cluster \n",
    "import json \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import CSDI, BRITS\n",
    "from pypots.utils.random import set_random_seed\n",
    "from pypots.utils.metrics import calc_mae\n",
    "import pickle\n",
    "import sys\n",
    "#sys.path.append(\"../../Interpolation/Imputation_Algs\")\n",
    "from cdrec.python.recovery import centroid_recovery as CDrec\n",
    "set_random_seed(1234)\n",
    "# check that GPU acceleration is enabled\n",
    "import torch\n",
    "#torch.cuda.device_count()\n",
    "#print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "#print(f\"CUDA ENABLED: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_folds_cdrec(Xs, ys, fold_idxs, window_idxs):\n",
    "    fold_scores = dict()\n",
    "    for fold in range(0, len(fold_idxs)):\n",
    "        print(f\"Evaluating fold {fold}/{len(fold_idxs)-1}...\")\n",
    "        # make the splits\n",
    "        X_train_fold = Xs[fold_idxs[fold][\"train\"]]\n",
    "        y_train_fold = ys[fold_idxs[fold][\"train\"]]\n",
    "        X_test_fold = Xs[fold_idxs[fold][\"test\"]]\n",
    "        y_test_fold = ys[fold_idxs[fold][\"test\"]]\n",
    "        # check class distributions\n",
    "        counts_tr = np.unique(y_train_fold, return_counts=True)[1]\n",
    "        print(f\"Training class distribution: {counts_tr/np.sum(counts_tr)}\")\n",
    "        counts_te = np.unique(y_test_fold, return_counts=True)[1]\n",
    "        print(f\"Testing class distribution: {counts_te/np.sum(counts_te)}\")\n",
    "        print(f\"Computing CDrec on fold {fold}...\")\n",
    "        percent_missing_score = dict()\n",
    "        for pm in window_idxs:\n",
    "            print(f\"Imputing {pm}% missing data over {len(window_idxs[pm])} windows...\")\n",
    "            per_window_scores = dict()\n",
    "            for (idx, widx) in enumerate(window_idxs[pm]):\n",
    "                X_test_corrupted = X_test_fold.copy()\n",
    "                X_test_corrupted[:, widx] = np.nan\n",
    "                mask = np.isnan(X_test_corrupted) # mask ensures only misisng values are imputed\n",
    "                Xdata = np.concatenate([X_train_fold.squeeze(), X_test_corrupted.squeeze()])\n",
    "                cdrec_imputed_raw = CDrec(matrix=Xdata) # using default paramss\n",
    "                cdrec_imputed = cdrec_imputed_raw[X_train_fold.shape[0]:][:].reshape([-1, X_train_fold.shape[1], 1]) # only the test data from the concatenated matrix            \n",
    "                errs = [calc_mae(cdrec_imputed[i], X_test_fold[i], mask[i]) for i in range(0, X_test_fold.shape[0])] # get individual errors for uncertainty quantification\n",
    "                per_window_scores[idx] = errs\n",
    "            percent_missing_score[pm] = per_window_scores\n",
    "        fold_scores[fold] = percent_missing_score\n",
    "    return fold_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 24)\n",
      "(67,)\n",
      "(1029, 24)\n",
      "(1029,)\n",
      "(67, 24, 1)\n",
      "(1029, 24, 1)\n",
      "(1096, 24, 1)\n",
      "(1096,)\n"
     ]
    }
   ],
   "source": [
    "# load the original IPD Split \n",
    "train_f = np.loadtxt(\"../../Data/italypower/datasets/ItalyPowerDemand_TRAIN.txt\")\n",
    "test_f = np.loadtxt(\"../../Data/italypower/datasets/ItalyPowerDemand_TEST.txt\")\n",
    "X_train = train_f[:, 1:]\n",
    "y_train = train_f[:, 0]\n",
    "X_test = test_f[:, 1:]\n",
    "y_test = test_f[:, 0]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# reshape data for imputation models\n",
    "X_train_original = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_original =  X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train_original = y_train\n",
    "y_test_original = y_test\n",
    "print(X_train_original.shape)\n",
    "print(X_test_original.shape)\n",
    "\n",
    "# Combine the train and test splits for resampling\n",
    "Xs = np.vstack([X_train_original, X_test_original])\n",
    "print(Xs.shape)\n",
    "ys = np.concatenate([y_train_original, y_test_original])\n",
    "print(ys.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "(67, 24, 1)\n",
      "(1029, 24, 1)\n",
      "(67,)\n",
      "(1029,)\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# load resample fold indices\n",
    "with open(\"../../FinalBenchmarks/ItalyPower/Python/ipd_resample_folds_python_idx.json\", \"r\") as f:\n",
    "    resample_fold_idxs_f = json.load(f)\n",
    "resample_fold_idxs = {int(k): v for k, v in resample_fold_idxs_f.items()}\n",
    "print(resample_fold_idxs.keys())\n",
    "\n",
    "X_train_f1 = Xs[resample_fold_idxs[0][\"train\"]]\n",
    "X_test_f1 = Xs[resample_fold_idxs[0][\"test\"]]\n",
    "y_train_f1 = ys[resample_fold_idxs[0][\"train\"]]\n",
    "y_test_f1 = ys[resample_fold_idxs[0][\"test\"]]\n",
    "\n",
    "print(X_train_f1.shape)\n",
    "print(X_test_f1.shape)\n",
    "print(y_train_f1.shape)\n",
    "print(y_test_f1.shape)\n",
    "\n",
    "print(np.all(np.equal(X_train_f1, X_train_original)))\n",
    "print(np.all(np.equal(y_train_f1, y_train_original)))\n",
    "print(np.all(np.equal(X_test_f1, X_test_original)))\n",
    "print(np.all(np.equal(y_test_f1, y_test_original)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([5, 15, 25, 35, 45, 55, 65, 75, 85, 95])\n"
     ]
    }
   ],
   "source": [
    "# load imputation window indices\n",
    "with open(\"../../FinalBenchmarks/ItalyPower/Python/ipd_windows_python_idx.json\", \"r\") as f:\n",
    "    window_idxs_f = json.load(f)\n",
    "window_idxs = {int(float(k)*100): v for k, v in window_idxs_f.items()}\n",
    "print(window_idxs.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 0/29...\n",
      "Training class distribution: [0.50746269 0.49253731]\n",
      "Testing class distribution: [0.49854227 0.50145773]\n",
      "Computing CDrec on fold 0...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 1/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 1...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 2/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 2...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 3/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 3...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 4/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 4...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 5/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 5...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 6/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 6...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 7/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 7...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 8/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 8...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 9/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 9...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 10/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 10...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n",
      "Imputing 85% missing data over 4 windows...\n",
      "Imputing 95% missing data over 1 windows...\n",
      "Evaluating fold 11/29...\n",
      "Training class distribution: [0.49253731 0.50746269]\n",
      "Testing class distribution: [0.49951409 0.50048591]\n",
      "Computing CDrec on fold 11...\n",
      "Imputing 5% missing data over 15 windows...\n",
      "Imputing 15% missing data over 15 windows...\n",
      "Imputing 25% missing data over 15 windows...\n",
      "Imputing 35% missing data over 15 windows...\n",
      "Imputing 45% missing data over 13 windows...\n",
      "Imputing 55% missing data over 11 windows...\n",
      "Imputing 65% missing data over 8 windows...\n",
      "Imputing 75% missing data over 6 windows...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fold_scores_cdrec \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_folds_cdrec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample_fold_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_idxs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 25\u001b[0m, in \u001b[0;36mevaluate_folds_cdrec\u001b[0;34m(Xs, ys, fold_idxs, window_idxs)\u001b[0m\n\u001b[1;32m     23\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(X_test_corrupted) \u001b[38;5;66;03m# mask ensures only misisng values are imputed\u001b[39;00m\n\u001b[1;32m     24\u001b[0m Xdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X_train_fold\u001b[38;5;241m.\u001b[39msqueeze(), X_test_corrupted\u001b[38;5;241m.\u001b[39msqueeze()])\n\u001b[0;32m---> 25\u001b[0m cdrec_imputed_raw \u001b[38;5;241m=\u001b[39m \u001b[43mCDrec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# using default paramss\u001b[39;00m\n\u001b[1;32m     26\u001b[0m cdrec_imputed \u001b[38;5;241m=\u001b[39m cdrec_imputed_raw[X_train_fold\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:][:]\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_train_fold\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# only the test data from the concatenated matrix            \u001b[39;00m\n\u001b[1;32m     27\u001b[0m errs \u001b[38;5;241m=\u001b[39m [calc_mae(cdrec_imputed[i], X_test_fold[i], mask[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, X_test_fold\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])] \u001b[38;5;66;03m# get individual errors for uncertainty quantification\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/QuantumInspiredMLFinal/QuantumInspiredML/Interpolation/Imputation_Algs/cdrec/python/recovery.py:47\u001b[0m, in \u001b[0;36mcentroid_recovery\u001b[0;34m(matrix, truncation, maxIterations, threshold)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# perform truncated decomposition\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mcentroid_decomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m#make sure it doesn't fail, if it does - fail as well\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/QuantumInspiredMLFinal/QuantumInspiredML/Interpolation/Imputation_Algs/cdrec/python/recovery.py:150\u001b[0m, in \u001b[0;36mcentroid_decomposition\u001b[0;34m(matrix, truncation, SV)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# main loop - goes up till the truncation param (maximum of which is the # of columns)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, truncation):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# calculate the sign vector\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     Z \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_sign_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSV\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# calculate the column of R by X^T * Z / ||X^T * Z||\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     R_i \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m Z\n",
      "File \u001b[0;32m~/Desktop/QuantumInspiredMLFinal/QuantumInspiredML/Interpolation/Imputation_Algs/cdrec/python/recovery.py:180\u001b[0m, in \u001b[0;36mlocal_sign_vector\u001b[0;34m(matrix, Z)\u001b[0m\n\u001b[1;32m    177\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(matrix[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    178\u001b[0m eps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39meps\n\u001b[0;32m--> 180\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_sign_vector_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# calculate initial product of X^T * Z with the current version of Z\u001b[39;00m\n\u001b[1;32m    183\u001b[0m direction \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m Z\n",
      "File \u001b[0;32m~/Desktop/QuantumInspiredMLFinal/QuantumInspiredML/Interpolation/Imputation_Algs/cdrec/python/recovery.py:242\u001b[0m, in \u001b[0;36mlocal_sign_vector_init\u001b[0;34m(matrix, Z)\u001b[0m\n\u001b[1;32m    239\u001b[0m         Z[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, m):\n\u001b[0;32m--> 242\u001b[0m         direction[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Z[i] \u001b[38;5;241m*\u001b[39m matrix[i][j]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Z\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold_scores_cdrec = evaluate_folds_cdrec(Xs, ys, resample_fold_idxs, window_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = fold_scores_cdrec[0][5][0]\n",
    "for i in range(1, 15):\n",
    "    f1 = np.hstack([f1, fold_scores_cdrec[0][5][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
